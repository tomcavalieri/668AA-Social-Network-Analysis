{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EoREqh8QkUS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-MPBrw5QkUZ"
   },
   "outputs": [],
   "source": [
    "g = nx.read_edgelist('network_finale.csv', data=(('weight', int),('industry',int)) , delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTC2XLt-QkUd",
    "outputId": "4db0b5f0-1ce9-4e52-90cd-08c1d555b86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  14875\n",
      "Number of Edges:  43932\n"
     ]
    }
   ],
   "source": [
    "NNODES = g.number_of_nodes()\n",
    "NEDGES = g.number_of_edges()\n",
    "\n",
    "print(\"Number of Nodes: \", NNODES)\n",
    "print(\"Number of Edges: \", NEDGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NuxQq8sQkUi"
   },
   "outputs": [],
   "source": [
    "def get_local_clustering_coefficient(node):\n",
    "    return nx.clustering(g,node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RVdJJL6QkUl"
   },
   "outputs": [],
   "source": [
    "def get_nodes_from_community(comm):\n",
    "    return list(g.subgraph(comm).nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khlyI8E2QkUp"
   },
   "outputs": [],
   "source": [
    "def get_edge_data(edge):\n",
    "    return g.get_edge_data(edge[0], edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsOQxaxXQkUt"
   },
   "outputs": [],
   "source": [
    "def get_community_index_from_node(node):\n",
    "    to_ret = None\n",
    "\n",
    "    for idx, com in enumerate(communities_map):\n",
    "        if node in com:\n",
    "            to_ret = idx\n",
    "            break\n",
    "            \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpfnpmUNQkUx"
   },
   "source": [
    "#### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkgK08LKQkUy"
   },
   "outputs": [],
   "source": [
    "degrees = dict(g.degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZOl2Rw1QkU1"
   },
   "source": [
    "#### Triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZwOt1MLQkU1"
   },
   "outputs": [],
   "source": [
    "triangles = nx.triangles(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_fogl7SQkU4"
   },
   "source": [
    "#### Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PL89ALTQQkU5"
   },
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNJDXid0QkU8"
   },
   "outputs": [],
   "source": [
    "eigenvector_centrality = nx.eigenvector_centrality(g, weight='weight', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CymF8V-TQkVA"
   },
   "outputs": [],
   "source": [
    "pagerank_centrality = nx.pagerank(g, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gclJon9xQkVD"
   },
   "outputs": [],
   "source": [
    "closeness_centrality = nx.closeness_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4z7n5G8dQkVG"
   },
   "outputs": [],
   "source": [
    "harmonic_centrality = nx.harmonic_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mKoNxgZQkVJ"
   },
   "outputs": [],
   "source": [
    "betweenness_centrality = nx.betweenness_centrality(g, weight='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2FEP0o_QkVM"
   },
   "source": [
    "#### Communities (louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOE2t0TrQkVN"
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "with open (\"louvain.pickle\", \"rb\") as f:\n",
    "    Louvain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ha8B0ZITQkVQ"
   },
   "outputs": [],
   "source": [
    "communities_map = []\n",
    "\n",
    "for idx, com in enumerate(Louvain.communities):\n",
    "    links = get_nodes_from_community(com)\n",
    "    \n",
    "    communities_map.append(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwsKsTICQkVV"
   },
   "source": [
    "### Creo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6chp-1U8QkVV"
   },
   "outputs": [],
   "source": [
    "edge_list = list(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_aOSvV-QkVY"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3d0ab7df627e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0medge_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_edge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mindustry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'industry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'weight'"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "\n",
    "for idx, edge in enumerate(edge_list):\n",
    "    node_a = edge[0]\n",
    "    node_b = edge[1]\n",
    "    \n",
    "    edge_data = get_edge_data(edge)\n",
    "    \n",
    "    weight = edge_data['weight']\n",
    "    industry = edge_data['industry']\n",
    "    \n",
    "    triangles_a = triangles[node_a]\n",
    "    triangles_b = triangles[node_b]\n",
    "    triangles_avg = (triangles_a + triangles_b) / 2\n",
    "    \n",
    "    comm_a = get_community_index_from_node(node_a)\n",
    "    comm_b = get_community_index_from_node(node_b)\n",
    "    comm = 1 if comm_a == comm_b else 0\n",
    "    \n",
    "    cl_coeff_a = get_local_clustering_coefficient(node_a)\n",
    "    cl_coeff_b = get_local_clustering_coefficient(node_b)\n",
    "    cl_coeff_avg = (cl_coeff_a + cl_coeff_b) / 2\n",
    "    \n",
    "    degree_a = degrees[node_a]\n",
    "    degree_b = degrees[node_b]\n",
    "    degree_avg = (degree_a + degree_b) / 2\n",
    "    \n",
    "    degree_centr_a = degree_centrality[node_a]\n",
    "    degree_centr_b = degree_centrality[node_b]\n",
    "    degree_centr_avg = (degree_centr_a + degree_centr_b) / 2\n",
    "    \n",
    "    eig_centr_a = eigenvector_centrality[node_a]\n",
    "    eig_centr_b = eigenvector_centrality[node_b]\n",
    "    eig_centr_avg = (eig_centr_a + eig_centr_b) / 2\n",
    "    \n",
    "    pagerank_centr_a = pagerank_centrality[node_a]\n",
    "    pagerank_centr_b = pagerank_centrality[node_b]\n",
    "    pagerank_centr_avg = (pagerank_centr_a + pagerank_centr_b) / 2\n",
    "    \n",
    "    closeness_cent_a = closeness_centrality[node_a]\n",
    "    closeness_cent_b = closeness_centrality[node_b]\n",
    "    closeness_cent_avg = (closeness_cent_a + closeness_cent_b) / 2\n",
    "    \n",
    "    harmonic_centr_a = harmonic_centrality[node_a]\n",
    "    harmonic_centr_b = harmonic_centrality[node_b]\n",
    "    harmonic_centr_avg = (harmonic_centr_a + harmonic_centr_b) / 2\n",
    "    \n",
    "    betweenness_centr_a = betweenness_centrality[node_a]\n",
    "    betweenness_centr_b = betweenness_centrality[node_b]\n",
    "    betweenness_centr_avg = (betweenness_centr_a + betweenness_centr_b) / 2\n",
    "    \n",
    "    data1.append([\n",
    "        node_a, node_b,\n",
    "        weight, industry,\n",
    "        triangles_a, triangles_b,\n",
    "        comm_a, comm_b,\n",
    "        cl_coeff_a, cl_coeff_b,\n",
    "        degree_a, degree_b,\n",
    "        degree_centr_a, degree_centr_b,\n",
    "        eig_centr_a, eig_centr_b,\n",
    "        pagerank_centr_a, pagerank_centr_b,\n",
    "        closeness_cent_a, closeness_cent_b,\n",
    "        harmonic_centr_a, harmonic_centr_b,\n",
    "        betweenness_centr_a, betweenness_centr_b\n",
    "    ])\n",
    "    \n",
    "    data2.append([\n",
    "        node_a, node_b,\n",
    "        weight, industry,\n",
    "        triangles_avg,\n",
    "        comm,\n",
    "        cl_coeff_avg,\n",
    "        degree_avg,\n",
    "        degree_centr_avg,\n",
    "        eig_centr_avg,\n",
    "        pagerank_centr_avg,\n",
    "        closeness_cent_avg, \n",
    "        harmonic_centr_avg,\n",
    "        betweenness_centr_avg,\n",
    "    ])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5JfHngzQkVb"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data1, columns=[\n",
    "                                 'NODE_A', 'NODE_B', \n",
    "                                 'WEIGHT', 'INDUSTRY', \n",
    "                                 'TRIANGLES_A', 'TRIANGLES_B',\n",
    "                                 'COMM_A', 'COMM_B', \n",
    "                                 'CL_COEF_A', 'CL_COEF_B', \n",
    "                                 'DEGREE_A', 'DEGREE_B', \n",
    "                                 'DEGREE_CENTR_A', 'DEGREE_CENTRALITY_B',\n",
    "                                 'EIGENVECTOR_CENTR_A', 'EIGENVECTOR_CENTR_B',\n",
    "                                 'PAGERANK_CENTR_A', 'PAGERANK_CENTR_B',\n",
    "                                 'CLOSENESS_CENTR_A', 'CLOSENESS_CENTR_B',\n",
    "                                 'HARMONIC_CENTR_A', 'HARMONIC_CENTR_B',\n",
    "                                 'BETWEENESS_CENTR_A', 'BETWEENESS_CENTR_B'\n",
    "                                ])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(data2, columns=[\n",
    "                                 'NODE_A', 'NODE_B', \n",
    "                                 'WEIGHT', 'INDUSTRY', \n",
    "                                 'TRIANGLES_AVG', \n",
    "                                 'COMM',\n",
    "                                 'CL_COEF_AVG',\n",
    "                                 'DEGREE_AVG', \n",
    "                                 'DEGREE_CENTR_AVG',\n",
    "                                 'EIGENVECTOR_CENTR_AVG',\n",
    "                                 'PAGERANK_CENTR_AVG', \n",
    "                                 'CLOSENESS_CENTR_AVG', \n",
    "                                 'HARMONIC_CENTR_AVG', \n",
    "                                 'BETWEENESS_CENTR_AVG'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzaZmc5SQkVe",
    "outputId": "e1453ebd-1c73-4225-fbfb-f8bcce0c3212"
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU8jysZxQkVh",
    "outputId": "823c71c0-4bda-4532-f2a7-1fc4ab6552ec"
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df1.iterrows():\n",
    "    if row[\"COMM_A\"] >  row[\"COMM_B\"]:\n",
    "        #print(row[\"COMM_A\"], row[\"COMM_B\"])\n",
    "        temp = row[\"COMM_B\"]\n",
    "        df1.loc[i, \"COMM_B\"] = row[\"COMM_A\"]\n",
    "        df1.loc[i, \"COMM_A\"] = temp\n",
    "        #print(df2[\"COMM_A\"][i], df2[\"COMM_B\"][i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    lista.append(str(row[\"COMM_A\"])+\"_\"+str(row[\"COMM_B\"]))\n",
    "    \n",
    "    \n",
    "df1[\"COMM_UN\"] = pd.Series(lista)\n",
    "df2[\"COMM_UN\"] = pd.Series(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df[\"COMM_UN\"])\n",
    "df1 = df1.drop(\"COMM_A\", axis = 1)\n",
    "df1 = df1.drop(\"COMM_B\", axis = 1)\n",
    "df1 = df1.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df_average[\"COMM_UN\"])\n",
    "df2 = df_average.drop(\"COMM\", axis = 1)\n",
    "\n",
    "df2 = df_average.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJQHcUC8QkVq"
   },
   "outputs": [],
   "source": [
    "df1.to_csv('DF_ALL_NEW_COMM.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgqgT1YvQkVs"
   },
   "outputs": [],
   "source": [
    "df2.to_csv('DF_AVG_NEW_COMM.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Dataset creator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
